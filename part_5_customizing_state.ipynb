{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a5734e",
   "metadata": {},
   "source": [
    "So far, we've relied on a simple state with one entry-- a list of messages. You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. Here we will demonstrate a new scenario, in which the chatbot is using its search tool to find specific information, and forwarding them to a human for review. Let's have the chatbot research the birthday of an entity. We will add name and birthday keys to the state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acda4b1",
   "metadata": {},
   "source": [
    "Adding this information to the state makes it easily accessible by other graph nodes (e.g., a downstream node that stores or processes the information), as well as the graph's persistence layer.\n",
    "\n",
    "Here, we will populate the state keys inside of our human_assistance tool. This allows a human to review the information before it is stored in the state. We will again use Command, this time to issue a state update from inside our tool. Read more about use cases for Command here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6aec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5bee8",
   "metadata": {},
   "source": [
    "Otherwise, the rest of our graph is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f866c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65226bb",
   "metadata": {},
   "source": [
    "Let's prompt our application to look up the \"birthday\" of the LangGraph library. We will direct the chatbot to reach out to the human_assistance tool once it has the required information. Note that setting name and birthday in the arguments for the tool, we force the chatbot to generate proposals for these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b9bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'll start by searching for information about LangGraph's release using the Tavily search engine, and then I'll use the human_assistance tool for review. Let's begin with the search.\", 'type': 'text'}, {'id': 'toolu_01AXbp1k1iKhfbxeWXtFjBUU', 'input': {'query': 'LangGraph release date'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01AXbp1k1iKhfbxeWXtFjBUU)\n",
      " Call ID: toolu_01AXbp1k1iKhfbxeWXtFjBUU\n",
      "  Args:\n",
      "    query: LangGraph release date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-20)To summarize:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-21)1. LangGraph's original release date: January 17, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-22)2. LangGraph Cloud announcement: June 27, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-23) [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-18)LangGraph was initially released on January 17, 2024. This information comes from the human assistance correction, which is more accurate than the search results I initially found.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-19) [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-24)It's worth noting that LangGraph had been in development and use for some time before the LangGraph Cloud announcement, but the official initial release of LangGraph itself was on January 17, 2024.\\nNote that these fields are now reflected in the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-1)snapshot = graph.get_state(config)\", \"score\": 0.92715925}, {\"title\": \"Announcing LangGraph v0.1 & LangGraph Cloud: Running agents ...\", \"url\": \"https://blog.langchain.dev/langgraph-cloud/\", \"content\": \"We also have a new stable release of LangGraph. By LangChain 6 min read Jun 27, 2024. (Oct '24) Edit: Since the launch of LangGraph Cloud, we\", \"score\": 0.83932644}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Thank you for providing that information. Based on the search results, it appears that LangGraph was initially released on January 17, 2024. However, to ensure the accuracy of this information, I'll use the human_assistance tool for review.\", 'type': 'text'}, {'id': 'toolu_01T7r94urdQV1kUk6o8DusCV', 'input': {'name': 'LangGraph', 'birthday': 'January 17, 2024'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01T7r94urdQV1kUk6o8DusCV)\n",
      " Call ID: toolu_01T7r94urdQV1kUk6o8DusCV\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: January 17, 2024\n"
     ]
    }
   ],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e365190",
   "metadata": {},
   "source": [
    "We've hit the interrupt in the human_assistance tool again. In this case, the chatbot failed to identify the correct date, so we can supply it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9dc8a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Thank you for providing that information. Based on the search results, it appears that LangGraph was initially released on January 17, 2024. However, to ensure the accuracy of this information, I'll use the human_assistance tool for review.\", 'type': 'text'}, {'id': 'toolu_01T7r94urdQV1kUk6o8DusCV', 'input': {'name': 'LangGraph', 'birthday': 'January 17, 2024'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01T7r94urdQV1kUk6o8DusCV)\n",
      " Call ID: toolu_01T7r94urdQV1kUk6o8DusCV\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: January 17, 2024\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the human assistance. The human review has confirmed that the information is correct, with a slight modification to the date format. \n",
      "\n",
      "To summarize:\n",
      "LangGraph was released on Jan 17, 2024.\n",
      "\n",
      "This date has been verified by both the initial search results and the human assistance review. The human assistance tool provided a slight correction to the date format, changing it from \"January 17, 2024\" to \"Jan 17, 2024\", but the actual date remains the same.\n",
      "\n",
      "Is there anything else you would like to know about LangGraph or its release?\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba81c7",
   "metadata": {},
   "source": [
    "Note that these fields are now reflected in the state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc1e33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bb4f1",
   "metadata": {},
   "source": [
    "This makes them easily accessible to downstream nodes (e.g., a node that further processes or stores the information)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8f617",
   "metadata": {},
   "source": [
    "#### Manually updating state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fdfa0c",
   "metadata": {},
   "source": [
    "LangGraph gives a high degree of control over the application state. For instance, at any point (including when interrupted), we can manually override a key using graph.update_state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b10196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f01caa9-4726-6d9b-8007-325140c95d64'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph library\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1819d",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "If we call graph.get_state, we can see the new value is reflected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937f4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph library', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92234a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
